{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "class DatasetType(Enum):\n",
    "    TRAIN = \"train\"\n",
    "    DEV = \"dev\"\n",
    "    TEST = \"test\"\n",
    "\n",
    "def shuffle_in_groups(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    zipped = list(zip(a, b))\n",
    "    random.shuffle(zipped)\n",
    "    return zip(*zipped)\n",
    "\n",
    "class Singleton(type):\n",
    "    _instances = {}\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        if self not in self._instances:\n",
    "            self._instances[self] = super().__call__(*args, **kwargs)\n",
    "        return self._instances[self]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, IterableDataset, get_worker_info\n",
    "\n",
    "LABEL_SILENCE = \"__silence__\"\n",
    "LABEL_UNKNOWN = \"__unknown__\"\n",
    "\n",
    "class GSCDatasetPreprocessor(metaclass=Singleton):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        # organize audio files by class\n",
    "        unknown_class_name = \"_UNKNOWN_\"\n",
    "\n",
    "        audio_files_by_class = {}\n",
    "        audio_counts_by_class = {}\n",
    "\n",
    "        for class_path in Path(config[\"data_dir\"]).iterdir():\n",
    "\n",
    "            if not class_path.is_dir():\n",
    "                continue\n",
    "\n",
    "            class_name = class_path.name\n",
    "\n",
    "            if class_name not in config[\"target_class\"] and class_name != \"_background_noise_\":\n",
    "                class_name = unknown_class_name\n",
    "\n",
    "            if class_name not in audio_files_by_class:\n",
    "                audio_files_by_class[class_name] = []\n",
    "                audio_counts_by_class[class_name] = 0\n",
    "\n",
    "            count = 0\n",
    "            for file_path in class_path.iterdir():\n",
    "\n",
    "                if \".wav\" != file_path.suffix:\n",
    "                    continue\n",
    "\n",
    "                count += 1\n",
    "                audio_files_by_class[class_name].append(file_path.as_posix())\n",
    "\n",
    "            audio_counts_by_class[class_name] += count\n",
    "\n",
    "        noise_files = audio_files_by_class.pop(\"_background_noise_\")\n",
    "\n",
    "        # split the dataset into trian/dev/test\n",
    "        self.bucket_size = 2**27 - 1\n",
    "        self.dev_pct = config[\"dev_pct\"]\n",
    "        self.test_pct = config[\"test_pct\"]\n",
    "\n",
    "        self.audio_files_by_dataset = {\n",
    "            DatasetType.TRAIN: [],\n",
    "            DatasetType.DEV: [],\n",
    "            DatasetType.TEST: []\n",
    "        }\n",
    "        self.labels_by_dataset = {\n",
    "            DatasetType.TRAIN: [],\n",
    "            DatasetType.DEV: [],\n",
    "            DatasetType.TEST: []\n",
    "        }\n",
    "        self.label_mapping = {}\n",
    "\n",
    "        # target class\n",
    "        for class_name in config[\"target_class\"]:\n",
    "            audio_list = audio_files_by_class[class_name]\n",
    "\n",
    "            label = config[\"target_class\"].index(class_name)\n",
    "            self.label_mapping[label] = class_name\n",
    "\n",
    "            for audio_file in audio_list:\n",
    "                bucket = self.get_bucket_from_file_name(audio_file, config[\"group_speakers_by_id\"])\n",
    "                self.distribute_to_dataset(bucket, audio_file, label)\n",
    "\n",
    "        # unknown class\n",
    "        if config[\"unknown_class\"]:\n",
    "            unknown_label = len(config[\"target_class\"])\n",
    "            for dataset in DatasetType:\n",
    "                unknown_size = int(len(self.labels_by_dataset[dataset]) / len(self.label_mapping.keys()))\n",
    "                self.audio_files_by_dataset[dataset] += random.sample(audio_files_by_class[unknown_class_name], unknown_size)\n",
    "                self.labels_by_dataset[dataset] += ([unknown_label] * unknown_size)\n",
    "            self.label_mapping[unknown_label] = LABEL_UNKNOWN\n",
    "\n",
    "        # silence class\n",
    "        if config[\"silence_class\"]:\n",
    "            silence_label = len(config[\"target_class\"]) + 1\n",
    "            for dataset in DatasetType:\n",
    "                silence_size = int(len(self.labels_by_dataset[dataset]) / len(self.label_mapping.keys()))\n",
    "                self.audio_files_by_dataset[dataset] += ([LABEL_SILENCE] * silence_size)\n",
    "                self.labels_by_dataset[dataset] += ([silence_label] * silence_size)\n",
    "            self.label_mapping[silence_label] = LABEL_SILENCE\n",
    "\n",
    "        # noise samples\n",
    "        self.noise_samples_by_dataset = {\n",
    "            DatasetType.TRAIN: [],\n",
    "            DatasetType.DEV: [],\n",
    "            DatasetType.TEST: []\n",
    "        }\n",
    "\n",
    "        sample_rate = config[\"sample_rate\"]\n",
    "        for file_name in noise_files:\n",
    "            full_noise = librosa.core.load(file_name, sr=sample_rate)[0]\n",
    "            for i in range(0, len(full_noise)-sample_rate, sample_rate):\n",
    "                noise_sample = full_noise[i:i + sample_rate] * random.random()\n",
    "\n",
    "                bucket = random.random()\n",
    "                if bucket < self.test_pct:\n",
    "                    self.noise_samples_by_dataset[DatasetType.TEST].append(noise_sample)\n",
    "                elif bucket < self.dev_pct + self.test_pct:\n",
    "                    self.noise_samples_by_dataset[DatasetType.DEV].append(noise_sample)\n",
    "                else:\n",
    "                    self.noise_samples_by_dataset[DatasetType.TRAIN].append(noise_sample)\n",
    "\n",
    "\n",
    "    def get_bucket_from_file_name(self, audio_file, group_speakers_by_id):\n",
    "        if group_speakers_by_id:\n",
    "            hashname_search = re.search(r\"(\\w+)_nohash_.*$\", audio_file, re.IGNORECASE)\n",
    "            if hashname_search:\n",
    "                hashname = hashname_search.group(1)\n",
    "\n",
    "            sha = int(hashlib.sha1(hashname.encode()).hexdigest(), 16)\n",
    "            bucket = (sha % (self.bucket_size + 1)) / self.bucket_size\n",
    "        else:\n",
    "            bucket = random.random()\n",
    "\n",
    "        return bucket\n",
    "\n",
    "    def distribute_to_dataset(self, bucket, audio_file, label):\n",
    "        if bucket < self.test_pct:\n",
    "            self.audio_files_by_dataset[DatasetType.TEST].append(audio_file)\n",
    "            self.labels_by_dataset[DatasetType.TEST].append(label)\n",
    "        elif bucket < self.dev_pct + self.test_pct:\n",
    "            self.audio_files_by_dataset[DatasetType.DEV].append(audio_file)\n",
    "            self.labels_by_dataset[DatasetType.DEV].append(label)\n",
    "        else:\n",
    "            self.audio_files_by_dataset[DatasetType.TRAIN].append(audio_file)\n",
    "            self.labels_by_dataset[DatasetType.TRAIN].append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_iter(seq, window_size, step_size):\n",
    "    it = iter(seq)\n",
    "    result = tuple(islice(it, window_size, step_size))\n",
    "    if len(result) == window_size:\n",
    "        print('r', result)\n",
    "        yield result    \n",
    "    for elem in it:\n",
    "        result = result[1:] + (elem,)\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_averages(values, size, step):\n",
    "    for selection in window_iter(values, size, step):\n",
    "        print(selection)\n",
    "        yield sum(selection) / size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6,)\n",
      "(26,)\n",
      "1.2 5.2\n",
      "(7,)\n",
      "(27,)\n",
      "1.4 5.4\n",
      "(8,)\n",
      "(28,)\n",
      "1.6 5.6\n",
      "(9,)\n",
      "(29,)\n",
      "1.8 5.8\n",
      "(10,)\n",
      "(210,)\n",
      "2.0 42.0\n"
     ]
    }
   ],
   "source": [
    "y = ['1', '2', '3', '4','5','6','7','8','9','10']\n",
    "y2 = ['21', '22', '23', '24','25','26','27','28','29','210']\n",
    "for p1,p2 in zip(moving_averages(map(int, y), 5, 1), moving_averages(map(int, y2), 5, 1)):\n",
    "    print(p1,p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
